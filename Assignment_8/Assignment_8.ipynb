{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b81c2faa",
        "outputId": "4c5c7e37-1e5f-47f4-f8c9-ec5766645a32"
      },
      "source": [
        "pip install nltk"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1af0068e",
        "outputId": "962457f0-81fe-425a-d5d1-23e90c7a1bac"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ca917f6",
        "outputId": "2d32b320-fbbe-4389-96c8-56294aa347c4"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "928b49d6",
        "outputId": "215b35f9-41bc-4c36-9329-86360f807d39"
      },
      "source": [
        "print(\"The NLTK library is installed and the 'wordnet' and 'punkt' corpora have been downloaded. The subtask is complete.\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The NLTK library is installed and the 'wordnet' and 'punkt' corpora have been downloaded. The subtask is complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49f358d1",
        "outputId": "56aa8efe-2ffd-435e-810e-43625577214e"
      },
      "source": [
        "ambiguous_sentence = \"The bank is located near the river.\"\n",
        "target_word = \"bank\"\n",
        "\n",
        "print(f\"Ambiguous Sentence: {ambiguous_sentence}\")\n",
        "print(f\"Target Word for Disambiguation: {target_word}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ambiguous Sentence: The bank is located near the river.\n",
            "Target Word for Disambiguation: bank\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5918c181",
        "outputId": "c8d1cdb5-e3aa-4a64-8368-10a2aa347791"
      },
      "source": [
        "nltk.download('punkt_tab')\n",
        "print(\"Downloaded 'punkt_tab' resource.\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded 'punkt_tab' resource.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c41aabd"
      },
      "source": [
        "**Reasoning**:\n",
        "Since the 'punkt_tab' resource has now been successfully downloaded, I will re-execute the original code block to perform tokenization and Part-of-Speech tagging, which should now run without the previous `LookupError`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cf1f16c",
        "outputId": "e1bd5098-bf96-44eb-f09e-7850aabaa93e"
      },
      "source": [
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "print(\"Downloaded 'averaged_perceptron_tagger_eng' resource.\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded 'averaged_perceptron_tagger_eng' resource.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5455be7",
        "outputId": "3f2e1cd6-763e-4302-bfdc-9208c9b612bf"
      },
      "source": [
        "tokens = nltk.word_tokenize(ambiguous_sentence)\n",
        "pos_tags = nltk.pos_tag(tokens)\n",
        "\n",
        "print(f\"Tokens: {tokens}\")\n",
        "print(f\"POS Tags: {pos_tags}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['The', 'bank', 'is', 'located', 'near', 'the', 'river', '.']\n",
            "POS Tags: [('The', 'DT'), ('bank', 'NN'), ('is', 'VBZ'), ('located', 'VBN'), ('near', 'IN'), ('the', 'DT'), ('river', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f2fa869",
        "outputId": "fe082c12-46bf-428d-c0de-a64f268ddba9"
      },
      "source": [
        "from nltk.corpus import wordnet\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def disambiguate_word(sentence, target_word, pos_tags):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "\n",
        "    target_pos = None\n",
        "    for word, tag in pos_tags:\n",
        "        if word.lower() == target_word.lower():\n",
        "            if tag.startswith('N'):\n",
        "                target_pos = wordnet.NOUN\n",
        "            elif tag.startswith('V'):\n",
        "                target_pos = wordnet.VERB\n",
        "            elif tag.startswith('ADJ'):\n",
        "                target_pos = wordnet.ADJ\n",
        "            elif tag.startswith('R'):\n",
        "                target_pos = wordnet.ADV\n",
        "            break\n",
        "\n",
        "    best_synset = None\n",
        "    max_overlap = -1\n",
        "\n",
        "\n",
        "    sentence_tokens = [w.lower() for w in nltk.word_tokenize(sentence) if w.isalpha() and w.lower() != target_word.lower() and w.lower() not in stop_words]\n",
        "    sentence_set = set(sentence_tokens)\n",
        "\n",
        "\n",
        "    for synset in wordnet.synsets(target_word):\n",
        "        if target_pos and synset.pos() != target_pos:\n",
        "            continue\n",
        "\n",
        "\n",
        "        gloss = synset.definition()\n",
        "        examples = ' '.join(synset.examples())\n",
        "\n",
        "\n",
        "        synset_text = gloss + ' ' + examples\n",
        "        synset_tokens = [w.lower() for w in nltk.word_tokenize(synset_text) if w.isalpha() and w.lower() not in stop_words]\n",
        "        synset_set = set(synset_tokens)\n",
        "\n",
        "\n",
        "        overlap = len(sentence_set.intersection(synset_set))\n",
        "\n",
        "        if overlap > max_overlap:\n",
        "            max_overlap = overlap\n",
        "            best_synset = synset\n",
        "\n",
        "    return best_synset\n",
        "\n",
        "print(\"The 'disambiguate_word' function has been defined.\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The 'disambiguate_word' function has been defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aab9128",
        "outputId": "b67e2866-2a49-4cca-b903-057c976b3d81"
      },
      "source": [
        "best_sense = disambiguate_word(ambiguous_sentence, target_word, pos_tags)\n",
        "\n",
        "if best_sense:\n",
        "    print(f\"The most likely sense for '{target_word}' in the sentence is: {best_sense.name()} ({best_sense.definition()})\")\n",
        "else:\n",
        "    print(f\"Could not disambiguate sense for '{target_word}'.\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The most likely sense for 'bank' in the sentence is: bank.n.01 (sloping land (especially the slope beside a body of water))\n"
          ]
        }
      ]
    }
  ]
}